{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crinstaniev/opt/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.core.environment.data_loader import DataLoader\n",
    "from src.core.model.encoders.multimodal_encoder import MultimodalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "['meridian-art-blocks-playground', 'cyberkongz-babies', 'cryptodickbutts', 'veefriends-series-2', 'Decentraland', 'cyberkongz-vx', 'killabears', 'curio-cards', 'meebits', 'memories-of-qilin-art-blocks-curated', 'the-potatoz', 'degods', 'hv-mtl-nft', 'cyberkongz-genesis', 'terraforms-by-mathcastles', 'onchainmonkey', 'doodles', 'murakami-flowers', 'pudgy-penguins', 'youtherealmvp', 'live-like-a-cat-nekonoyouniikiru', 'world-of-women', 'cryptoninja-partners', 'renga', 'veefriends', 'damien-hirst-the-currency', 'io-imaginary-ones', 'friendship-bracelets-by-alexis-andre', 'nft-worlds', 'eulerbeats-genesis-original', 'the_sandbox', 'the-singularity', 'fluf-world', 'etheria', 'neo-tokyo-part-4-land-deeds', 'cryptopunks', 'kanpai-pandas', 'nakamigos', 'qql-mint-pass', 'invisible-friends', 'sappy-seals', 'elevated-deconstructions-art-blocks-curated', 'genesis-braindrops', 'gazers', 'opepen-edition-nft', 'v1-cryptopunks-wrapped', 'ringers-art-blocks-curated', 'milady', 'space-doodles', 'forgotten-runes-wizards-cult', 'otherdeed', 'digidaigaku', 'renga-black-box', 'proof-moonbirds', 'max-pain-and-frens-by-xcopy', 'mutant-ape-yacht-club', 'mocaverse', 'lil-pudgys', 'pixelmon-generation-1', 'deafbeef', 'valhalla', 'grifters-by-xcopy', 'cyberbrokers', 'fidenza-art-blocks-curated', 'rektguy', 'thecaptainz', 'the-eternal-pump', 'neo-tokyo-identities', 'incomplete-control-by-tyler-hobbs', 'mfers', 'loomlocknft', 'cryptoadz', 'rtfkt-egg-animus', 'the-memes-by-6529', 'proof-collective']\n"
     ]
    }
   ],
   "source": [
    "a = DataLoader(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, image, time_series = a.load_collection_features(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Meridian - Art Blocks Playground is an NFT collectible created by Matt DesLauriers that was released on 9-28-2021. The project consists of 1,000 unique digital items living on the Ethereum blockchain. We categorize it as a art project and it's part of the Art Blocks general collection and the Playground subcollection.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "        'This is a sample text to test the MultimodalEncoder module.'\n",
    "        for _ in range(1)\n",
    "    ]  # (batch_size, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a sample text to test the MultimodalEncoder module.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.0000e+00, 2.8305e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [7.0000e+00, 2.8690e+04, 2.0000e+00, 1.6990e+01, 6.9634e+04],\n",
       "         [6.9900e+00, 3.0046e+04, 3.0000e+00, 2.4990e+01, 1.0742e+05],\n",
       "         [6.9900e+00, 3.1101e+04, 2.0000e+00, 1.8050e+01, 8.0312e+04],\n",
       "         [6.9690e+00, 3.2311e+04, 3.0000e+00, 2.6000e+01, 1.2055e+05],\n",
       "         [6.9690e+00, 3.1966e+04, 2.0000e+00, 8.6969e+01, 3.9892e+05],\n",
       "         [6.9500e+00, 3.1376e+04, 2.0000e+00, 4.9000e+01, 2.2121e+05],\n",
       "         [6.2500e+00, 2.6352e+04, 3.0000e+00, 2.0000e+01, 8.4326e+04],\n",
       "         [5.7500e+00, 2.3708e+04, 2.0000e+00, 1.3750e+01, 5.6693e+04],\n",
       "         [6.5000e+00, 2.7321e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [6.0000e+00, 2.6125e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [6.0000e+00, 2.5861e+04, 2.0000e+00, 1.3890e+01, 5.9869e+04],\n",
       "         [6.0000e+00, 2.6646e+04, 2.0000e+00, 1.5000e+01, 6.6614e+04],\n",
       "         [6.0000e+00, 2.4920e+04, 3.0000e+00, 1.9000e+01, 7.8913e+04],\n",
       "         [6.5000e+00, 2.5468e+04, 1.0000e+00, 9.0000e+00, 3.5264e+04],\n",
       "         [6.2500e+00, 2.5499e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: torch.Size([1, 16, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[39m=\u001b[39m encoder(time_series, image, text)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Courses/STATS402/src/core/model/encoders/multimodal_encoder.py:36\u001b[0m, in \u001b[0;36mMultimodalEncoder.forward\u001b[0;34m(self, time_series, image, text)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, time_series, image, text):\n\u001b[0;32m---> 36\u001b[0m     time_series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mts_encoder(time_series)\n\u001b[1;32m     37\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_encoder(image)\n\u001b[1;32m     38\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_encoder(text)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Courses/STATS402/src/core/model/encoders/../../../core/model/encoders/ts_encoder.py:34\u001b[0m, in \u001b[0;36mTimeSeriesEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msize:\u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39msize())\n\u001b[1;32m     31\u001b[0m batch_size, timesteps, _ \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()\n\u001b[0;32m---> 34\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_embedding(x)\n\u001b[1;32m     35\u001b[0m pos_enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_encoding\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, timesteps, \u001b[39m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m pos_enc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "output = encoder(time_series, image, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
